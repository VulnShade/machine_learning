{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Neural Network Tensorflow implementation\n",
    "Handwritten digit recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from utils.autils import *\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Use a neural network to recognize two handwritten digits, zero and one. This is a binary classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "You will start by loading the dataset for this task. \n",
    "- The `load_data()` function shown below loads the data into variables `X` and `y`\n",
    "\n",
    "\n",
    "- The data set contains 1000 training examples of handwritten digits $^1$, here limited to zero and one.  \n",
    "\n",
    "    - Each training example is a 20-pixel x 20-pixel grayscale image of the digit. \n",
    "        - Each pixel is represented by a floating-point number indicating the grayscale intensity at that location. \n",
    "        - The 20 by 20 grid of pixels is “unrolled” into a 400-dimensional vector. \n",
    "        - Each training example becomes a single row in our data matrix `X`. \n",
    "        - This gives us a 1000 x 400 matrix `X` where every row is a training example of a handwritten digit image.\n",
    "\n",
    "$$X = \n",
    "\\left(\\begin{array}{cc} \n",
    "--- (x^{(1)}) --- \\\\\n",
    "--- (x^{(2)}) --- \\\\\n",
    "\\vdots \\\\ \n",
    "--- (x^{(m)}) --- \n",
    "\\end{array}\\right)$$ \n",
    "\n",
    "- The second part of the training set is a 1000 x 1 dimensional vector `y` that contains labels for the training set\n",
    "    - `y = 0` if the image is of the digit `0`, `y = 1` if the image is of the digit `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### View the variables\n",
    "Let's get more familiar with your dataset.  \n",
    "- A good place to start is to print out each variable and see what it contains.\n",
    "\n",
    "The code below prints elements of the variables `X` and `y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('The first element of X is: ', X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('The first element of y is: ', y[0,0])\n",
    "print ('The last element of y is: ', y[-1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "#### Check the dimensions of your variables\n",
    "\n",
    "Another way to get familiar with your data is to view its dimensions. Please print the shape of `X` and `y` and see how many training examples you have in your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Visualizing the Data\n",
    "\n",
    "You will begin by visualizing a subset of the training set. \n",
    "- In the cell below, the code randomly selects 64 rows from `X`, maps each row back to a 20 pixel by 20 pixel grayscale image and displays the images together. \n",
    "- The label for each image is displayed above the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# You do not need to modify anything in this cell\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(8,8))\n",
    "fig.tight_layout(pad=0.1)\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # Select random indices\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    # Select rows corresponding to the random indices and\n",
    "    # reshape the image\n",
    "    X_random_reshaped = X[random_index].reshape((20,20)).T\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "    \n",
    "    # Display the label above the image\n",
    "    ax.set_title(y[random_index,0])\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Model representation\n",
    "\n",
    "The neural network you will use in this assignment is shown in the figure below. \n",
    "- This has three dense layers with sigmoid activations.\n",
    "    - Recall that our inputs are pixel values of digit images.\n",
    "    - Since the images are of size $20\\times20$, this gives us $400$ inputs  \n",
    "    \n",
    "<img src=\"images/C2_W1_Assign1.PNG\" width=\"500\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "- The parameters have dimensions that are sized for a neural network with $25$ units in layer 1, $15$ units in layer 2 and $1$ output unit in layer 3. \n",
    "\n",
    "    - Recall that the dimensions of these parameters are determined as follows:\n",
    "        - If network has $s_{in}$ units in a layer and $s_{out}$ units in the next layer, then \n",
    "            - $W$ will be of dimension $s_{in} \\times s_{out}$.\n",
    "            - $b$ will a vector with $s_{out}$ elements\n",
    "  \n",
    "    - Therefore, the shapes of `W`, and `b`,  are \n",
    "        - layer1: The shape of `W1` is (400, 25) and the shape of `b1` is (25,)\n",
    "        - layer2: The shape of `W2` is (25, 15) and the shape of `b2` is: (15,)\n",
    "        - layer3: The shape of `W3` is (15, 1) and the shape of `b3` is: (1,)\n",
    ">**Note:** The bias vector `b` could be represented as a 1-D (n,) or 2-D (1,n) array. Tensorflow utilizes a 1-D representation and this lab will maintain that convention. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Tensorflow Model Implementation\n",
    "Tensorflow models are built layer by layer. A layer's input dimensions ($s_{in}$ above) are calculated for you. You specify a layer's *output dimensions* and this determines the next layer's input dimension. The input dimension of the first layer is derived from the size of the input data specified in the `model.fit` statement below. \n",
    ">**Note:** It is also possible to add an input layer that specifies the input dimension of the first layer. For example:  \n",
    "`tf.keras.Input(shape=(400,)),    #specify input shape`  \n",
    "We will include that here to illuminate some model sizing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Below, using Keras [Sequential model](https://keras.io/guides/sequential_model/) and [Dense Layer](https://keras.io/api/layers/core_layers/dense/) with a sigmoid activation to construct the network described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape=(400,)),    #specify input size\n",
    "        tf.keras.layers.Dense(25, activation=\"sigmoid\"),\n",
    "        tf.keras.layers.Dense(15, activation=\"sigmoid\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ], name = \"my_model\" \n",
    ")                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "We can examine details of the model by first extracting the layers with `model.layers` and then extracting the weights with `layerx.get_weights()` as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "[layer1, layer2, layer3] = model.layers\n",
    "\n",
    "#### Examine Weights shapes\n",
    "W1,b1 = layer1.get_weights()\n",
    "W2,b2 = layer2.get_weights()\n",
    "W3,b3 = layer3.get_weights()\n",
    "print(f\"W1 shape = {W1.shape}, b1 shape = {b1.shape}\")\n",
    "print(f\"W2 shape = {W2.shape}, b2 shape = {b2.shape}\")\n",
    "print(f\"W3 shape = {W3.shape}, b3 shape = {b3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "xx.get_weights` returns a NumPy array. One can also access the weights directly in their tensor form. Note the shape of the tensors in the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers[2].weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "The following code will define a loss function and run gradient descent to fit the weights of the model to the training data. This will be explained in more detail in the following week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X,y,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "To run the model on an example to make a prediction, use [Keras `predict`](https://www.tensorflow.org/api_docs/python/tf/keras/Model). The input to `predict` is an array so the single example is reshaped to be two dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prediction >= 0.5:\n",
    "    yhat = 1\n",
    "else:\n",
    "    yhat = 0\n",
    "print(f\"prediction after threshold: {yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "The output of the model is interpreted as a probability. In the first example above, the input is a zero. The model predicts the probability that the input is a one is nearly zero. \n",
    "In the second example, the input is a one. The model predicts the probability that the input is a one is nearly one.\n",
    "As in the case of logistic regression, the probability is compared to a threshold to make a final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X[0].reshape(1,400))  # a zero\n",
    "print(f\" predicting a zero: {prediction}\")\n",
    "prediction = model.predict(X[500].reshape(1,400))  # a one\n",
    "print(f\" predicting a one:  {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Let's compare the predictions vs the labels for a random sample of 64 digits. This takes a moment to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# You do not need to modify anything in this cell\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(8,8))\n",
    "fig.tight_layout(pad=0.1,rect=[0, 0.03, 1, 0.92]) #[left, bottom, right, top]\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # Select random indices\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    # Select rows corresponding to the random indices and\n",
    "    # reshape the image\n",
    "    X_random_reshaped = X[random_index].reshape((20,20)).T\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "    \n",
    "    # Predict using the Neural Network\n",
    "    prediction = model.predict(X[random_index].reshape(1,400))\n",
    "    if prediction >= 0.5:\n",
    "        yhat = 1\n",
    "    else:\n",
    "        yhat = 0\n",
    "    \n",
    "    # Display the label above the image\n",
    "    ax.set_title(f\"{y[random_index,0]},{yhat}\")\n",
    "    ax.set_axis_off()\n",
    "fig.suptitle(\"Label, yhat\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
